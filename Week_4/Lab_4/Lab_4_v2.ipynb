{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "embed-resources: true\n",
    "title: \"544: Lab 3 assignment\"\n",
    "author: \"Andriy Uspishnyi\"\n",
    "date: \"2024-14-08\"\n",
    "output: \n",
    "  html_document:\n",
    "    theme: \"cosmo\" \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 4: https://kbodwin.github.io/GSB-544-private/Lab4.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Location Counts\n",
    "\n",
    "1. Use the beautifulsoup library to scrape the data (from the link above) on state names and corresponding number of store locations, for the following chains:\n",
    "- Starbucks\n",
    "- Dunkinâ€™ Donuts\n",
    "\n",
    "2. Parse, merge and tidy your data. Think carefully about what the tidy version of this dataset is with multiple years represented on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "response_st = re.get('https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "soup_st = BeautifulSoup(response_st.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "table_st = soup_st.find_all('table',\n",
    "                attrs={\n",
    "                    'class': 'wpr-table'\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creating function to scrape data and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# future function (to be called within a main function) in Step 4. Automation\n",
    "def ws_to_df(url):\n",
    "    # scraping the data with BeautifulSoup\n",
    "    response = re.get(url)\n",
    "    soup_table = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Parsing all rows from the table\n",
    "    rows = soup_table.find_all('tr')\n",
    "\n",
    "    # Extracting headers (if present)\n",
    "    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "    # Initializing a list for the table\n",
    "    table_data = []\n",
    "\n",
    "    # Looping through rows to extract data\n",
    "    for row in rows[1:]: # skipping header extracted in prior step\n",
    "        state = row.find('a').text\n",
    "        values = [state] + [td.text.strip().replace(',','') for td in row.find_all('td')] ## assisted by ChatGPT\n",
    "        table_data.append(values)\n",
    "    \n",
    "    # Creating dataframe\n",
    "    df = pd.DataFrame(table_data, columns=headers)\n",
    "    return(df)\n",
    "\n",
    "# note: Originally used an adjusted code from the PA assignment, however, while trying to fix a bug, managed to get a more elegant code suggestion from ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: For the purpose of analyzing 'current state of the market', it makes sense to focus only on all state data (without update to 2024, to avoid infalting the numbers - eg. opened +37 stores in 2024 in CA (reflected in the original data), but closed -5 stores in MN (not info on 2024 in table). Therefore, I'm going to use only original data for 2023 for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sb_df = ws_to_df('https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dd_df = ws_to_df('https://worldpopulationreview.com/state-rankings/dunkin-donuts-by-state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Starbucks data\n",
    "# sb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Dunkin Donuts data\n",
    "# dd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to partial data for Starbucks in 2024, and not data for Dunkin in 2021, it makes sense to limit the analysis only to most recent full data for 2023 for both brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sb_loc_2023 = sb_df[['State','Starbucks Stores 2023']]\n",
    "# sb_loc_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dd_loc_2023 = dd_df[['State','Dunkin Locations 2023']]\n",
    "# dd_loc_2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! fact check intervention !\n",
    "one thing easy thing to catch about Dunkin data is the change in number of locations between state of Washington and District of Columbia. After doublechecking on their website (https://locations.dunkindonuts.com/en) it looks like there are 19 stores in Washington D.C. but not in the state of Washington. Therefore, manually correcting this in the 'tidy' dataset for Dunkin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-13>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-13>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# reassigning the values in corresponding cells\n",
    "dd_loc_2023.iloc[36,1] = 19\n",
    "dd_loc_2023.iloc[50,1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# dd_loc_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# merging data for two chains by state\n",
    "merged_chains_df = pd.merge(sb_loc_2023, dd_loc_2023, on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# renaming one of the columns to match\n",
    "merged_chains_df = merged_chains_df.rename(columns={'Dunkin Locations 2023':'Dunkin Stores 2023'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Starbucks Stores 2023</th>\n",
       "      <th>Dunkin Stores 2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>3080</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1346</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>844</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>692</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Starbucks Stores 2023 Dunkin Stores 2023\n",
       "0  California                  3080                134\n",
       "1       Texas                  1346                196\n",
       "2     Florida                   844                883\n",
       "3  Washington                   741                  0\n",
       "4    New York                   692               1414"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_chains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supplemental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "response_wiki = re.get('https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "soup_wiki = BeautifulSoup(response_wiki.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Parsing table and creating dataframe. Note: assisted by ChatGPT\n",
    "states = []\n",
    "populations = []\n",
    "regions = []\n",
    "\n",
    "# Predefined vectors for each region\n",
    "Northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', 'Rhode Island', \n",
    "             'Vermont', 'New Jersey', 'New York', 'Pennsylvania']\n",
    "Midwest = ['Illinois', 'Indiana', 'Michigan', 'Ohio', 'Wisconsin', \n",
    "           'Iowa', 'Kansas', 'Minnesota', 'Missouri', 'Nebraska', \n",
    "           'North Dakota', 'South Dakota']\n",
    "South = ['Delaware', 'Florida', 'Georgia', 'Maryland', 'North Carolina', \n",
    "         'South Carolina', 'Virginia', 'District of Columbia', 'West Virginia', \n",
    "         'Alabama', 'Kentucky', 'Mississippi', 'Tennessee', 'Arkansas', \n",
    "         'Louisiana', 'Oklahoma', 'Texas']\n",
    "West = ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', \n",
    "        'New Mexico', 'Utah', 'Wyoming', 'Alaska', \n",
    "        'California', 'Hawaii', 'Oregon', 'Washington']\n",
    "\n",
    "# Function to assign region based on State to further use in the loop for creating a dataframe\n",
    "def get_region(state):\n",
    "    if state in Northeast:\n",
    "        return \"Northeast\"\n",
    "    elif state in Midwest:\n",
    "        return \"Midwest\"\n",
    "    elif state in South:\n",
    "        return \"South\"\n",
    "    elif state in West:\n",
    "        return \"West\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Looping through rows and extracting required columns\n",
    "for row in soup_wiki.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 4:\n",
    "        state = cols[2].get_text(strip=True)\n",
    "        population = cols[3].get_text(strip=True).replace(\",\", \"\")\n",
    "        region = get_region(state)\n",
    "        states.append(state)\n",
    "        populations.append(int(population))\n",
    "        regions.append(region)\n",
    "\n",
    "\n",
    "\n",
    "# Creating DataFrame\n",
    "df_pop = pd.DataFrame({\"State\": states, \"Population\": populations, \"Region\": regions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>39538223</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>30145505</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>21538187</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>20201249</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>13002700</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          State  Population     Region\n",
       "0    California    39538223       West\n",
       "1         Texas    30145505      South\n",
       "2       Florida    21538187      South\n",
       "3      New York    20201249  Northeast\n",
       "4  Pennsylvania    13002700  Northeast"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging datasets with chain locations and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_chains_df, df_pop, on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# chaning store location data to numeric\n",
    "merged_df['Starbucks Stores 2023'] = pd.to_numeric(merged_df['Starbucks Stores 2023'], errors='coerce')\n",
    "merged_df['Dunkin Stores 2023'] = pd.to_numeric(merged_df['Dunkin Stores 2023'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding financial information for companies:\n",
    "\n",
    "## NOTE: \n",
    "Considering there is barely any open, trustworthy and verifiable financial data available for Dunkin in 2023, after they were acquired by Arby's in 2020, this part of the analysis is rather limited, in order to keep it 'apples to apples' with Starbucks. Hence, the only reasonable 'metric' (from the same source: Zippia) that I found for for both business are 2023 revenues:\n",
    "\n",
    "    Dunkin Donuts: 1.4 (in billion USD) (source: https://www.zippia.com/dunkin-donuts-careers-554008/revenue/)\n",
    "    \n",
    "    Startbucks: 36.0 (in billion USD) (source: https://www.zippia.com/starbucks-careers-10803/revenue/)\n",
    "\n",
    "Other metrics from this source don't look accuarte, like number of employees etc.\n",
    "\n",
    "Based on this metric, I can estimate average revenue per open store and further by location and region.\n",
    "\n",
    "Most of other online data for Dunkin is from 2019 (before acquisition) and making a comparison between DNKN 2019 data and 2023 or even 2019 SBUX data is not relevant to their 2023 locations data (which likely has changed after the pandemic), which would make it an 'apples to oranges' comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dd_2023_revenue = 1.4*1000000000\n",
    "sb_2023_revenue = 36*1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# number of stores by brand\n",
    "sb_stores = merged_df['Starbucks Stores 2023'].sum()\n",
    "dd_stores = merged_df['Dunkin Stores 2023'].sum()\n",
    "# print(sb_stores, dd_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2441671 149557\n",
      "2441671 149557\n"
     ]
    }
   ],
   "source": [
    "# preliminary estimates based on revenue, before adding columns to merged_df\n",
    "sb_rev_per_store = round(sb_2023_revenue/sb_stores)\n",
    "dd_rev_per_store = round(dd_2023_revenue/dd_stores)\n",
    "print(sb_rev_per_store, dd_rev_per_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considering a vast difference in revenues, while comparable difference in number of stores in the US, it makes it hard to believe that the above results on average revenue per location are valid. However, given there's no better data found, I proceed with the analysis for the sake of this assignment, regardless of the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# adding new columns to dataset\n",
    "merged_df['Starbucks est. Revenue per State in Million USD'] = round(merged_df['Starbucks Stores 2023']*sb_rev_per_store/1000000, 2)\n",
    "merged_df['Dunkin est. Revenue per State in Million USD'] = round(merged_df['Dunkin Stores 2023']*dd_rev_per_store/1000000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Starbucks Stores 2023</th>\n",
       "      <th>Dunkin Stores 2023</th>\n",
       "      <th>Population</th>\n",
       "      <th>Region</th>\n",
       "      <th>Starbucks est. Revenue per State in Million USD</th>\n",
       "      <th>Dunkin est. Revenue per State in Million USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>3080</td>\n",
       "      <td>134</td>\n",
       "      <td>39538223</td>\n",
       "      <td>West</td>\n",
       "      <td>7520.35</td>\n",
       "      <td>20.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1346</td>\n",
       "      <td>196</td>\n",
       "      <td>30145505</td>\n",
       "      <td>South</td>\n",
       "      <td>3286.49</td>\n",
       "      <td>29.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>844</td>\n",
       "      <td>883</td>\n",
       "      <td>21538187</td>\n",
       "      <td>South</td>\n",
       "      <td>2060.77</td>\n",
       "      <td>132.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "      <td>7705281</td>\n",
       "      <td>West</td>\n",
       "      <td>1809.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>692</td>\n",
       "      <td>1414</td>\n",
       "      <td>20201249</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>1689.64</td>\n",
       "      <td>211.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  ...  Dunkin est. Revenue per State in Million USD\n",
       "0  California  ...                                         20.04\n",
       "1       Texas  ...                                         29.31\n",
       "2     Florida  ...                                        132.06\n",
       "3  Washington  ...                                          0.00\n",
       "4    New York  ...                                        211.47\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do some comparitive analysis with this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# What is the share of Strabucks and Dunkin stores per region?\n",
    "\n",
    "# How does it compare to the populations in each region?\n",
    "\n",
    "# How do revenues per region look like for each brand?\n",
    "\n",
    "# What is the average revenue per capita in each state (in $1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Starbucks Stores 2023</th>\n",
       "      <th>Dunkin Stores 2023</th>\n",
       "      <th>Population</th>\n",
       "      <th>Starbucks est. Revenue per State in Million USD</th>\n",
       "      <th>Dunkin est. Revenue per State in Million USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.100000e+01</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>289.098039</td>\n",
       "      <td>183.549020</td>\n",
       "      <td>6.518613e+06</td>\n",
       "      <td>705.882549</td>\n",
       "      <td>27.450392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>477.755722</td>\n",
       "      <td>303.876377</td>\n",
       "      <td>7.470225e+06</td>\n",
       "      <td>1166.522916</td>\n",
       "      <td>45.447110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.768510e+05</td>\n",
       "      <td>19.530000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>56.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.816411e+06</td>\n",
       "      <td>137.955000</td>\n",
       "      <td>2.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>131.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.505836e+06</td>\n",
       "      <td>319.860000</td>\n",
       "      <td>7.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>332.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>7.428392e+06</td>\n",
       "      <td>810.630000</td>\n",
       "      <td>30.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3080.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>3.953822e+07</td>\n",
       "      <td>7520.350000</td>\n",
       "      <td>211.470000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Starbucks Stores 2023  ...  Dunkin est. Revenue per State in Million USD\n",
       "count              51.000000  ...                                     51.000000\n",
       "mean              289.098039  ...                                     27.450392\n",
       "std               477.755722  ...                                     45.447110\n",
       "min                 8.000000  ...                                      0.000000\n",
       "25%                56.500000  ...                                      2.540000\n",
       "50%               131.000000  ...                                      7.480000\n",
       "75%               332.000000  ...                                     30.060000\n",
       "max              3080.000000  ...                                    211.470000\n",
       "\n",
       "[8 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Share of Strabucks and Dunkin stores per region # note: assisted by ChatGPT\n",
    "\n",
    "region_store_counts = merged_df.groupby('Region')[['Starbucks Stores 2023', 'Dunkin Stores 2023']].sum()\n",
    "\n",
    "# Calculate share of stores per region\n",
    "region_store_counts['Starbucks Stores Share (%)'] = (region_store_counts['Starbucks Stores 2023'] /\n",
    "                                             region_store_counts['Starbucks Stores 2023'].sum()) * 100\n",
    "region_store_counts['Dunkin Stores Share (%)'] = (region_store_counts['Dunkin Stores 2023'] /\n",
    "                                           region_store_counts['Dunkin Stores 2023'].sum()) * 100\n",
    "\n",
    "# print(region_store_counts[['Starbucks Stores Share (%)', 'Dunkin Stores Share (%)']])\n",
    "\n",
    "# note: I considered another option to do this analysis is using pd.crosstab, however it would require creating a dummy variable column eg. Starbucks = 1, Dunkin = 0. Given this approach would extend the number of rows, I opted not to do it. However, this would be possible with the dataset provided from automated function in part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Starbucks Stores Share (%)</th>\n",
       "      <th>Dunkin Stores Share (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>16.739012</td>\n",
       "      <td>14.934302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northeast</th>\n",
       "      <td>12.208356</td>\n",
       "      <td>53.872450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>30.880358</td>\n",
       "      <td>27.518428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>40.172273</td>\n",
       "      <td>3.674821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Starbucks Stores Share (%)  Dunkin Stores Share (%)\n",
       "Region                                                        \n",
       "Midwest                     16.739012                14.934302\n",
       "Northeast                   12.208356                53.872450\n",
       "South                       30.880358                27.518428\n",
       "West                        40.172273                 3.674821"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also can join these results into a dataframe\n",
    "stores_by_region = pd.DataFrame.join(region_store_counts['Starbucks Stores Share (%)'],region_store_counts['Dunkin Stores Share (%)'])\n",
    "stores_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Starbucks Stores per 100k people</th>\n",
       "      <th>Dunkin Stores per 100k people</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>3.577566</td>\n",
       "      <td>2.026514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northeast</th>\n",
       "      <td>3.124504</td>\n",
       "      <td>8.753818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>3.577543</td>\n",
       "      <td>2.024105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>7.536719</td>\n",
       "      <td>0.437723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Starbucks Stores per 100k people  Dunkin Stores per 100k people\n",
       "Region                                                                    \n",
       "Midwest                            3.577566                       2.026514\n",
       "Northeast                          3.124504                       8.753818\n",
       "South                              3.577543                       2.024105\n",
       "West                               7.536719                       0.437723"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does the number of stores compare to the populations in each region? # note: assisted by ChatGPT\n",
    "region_pop = merged_df.groupby('Region')['Population'].sum()\n",
    "stores_to_pop = pd.concat([region_store_counts[['Starbucks Stores 2023', 'Dunkin Stores 2023']], region_pop], axis=1)\n",
    "\n",
    "# Store count per capita (number of stores per 100,000 people for easier interpretation)\n",
    "stores_to_pop['Starbucks Stores per 100k people'] = stores_to_pop['Starbucks Stores 2023'] / (stores_to_pop['Population']/100000)\n",
    "stores_to_pop['Dunkin Stores per 100k people'] = stores_to_pop['Dunkin Stores 2023'] / (stores_to_pop['Population']/100000)\n",
    "\n",
    "reg_stores_per_capita = pd.DataFrame.join(stores_to_pop['Starbucks Stores per 100k people'],stores_to_pop['Dunkin Stores per 100k people'])\n",
    "reg_stores_per_capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Dunkin has significantly more stores in Northeast compared to other regions, while Starbucks in the West. Which is not surprising given both brands origins. However, what was quite surprising is a relatively low presence of Dunkin stores in the West, also when compared to population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Starbucks est. Revenue per State in Million USD</th>\n",
       "      <th>Dunkin est. Revenue per State in Million USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>6026.04</td>\n",
       "      <td>209.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northeast</th>\n",
       "      <td>4395.03</td>\n",
       "      <td>754.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>11116.91</td>\n",
       "      <td>385.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>14462.03</td>\n",
       "      <td>51.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Starbucks est. Revenue per State in Million USD  Dunkin est. Revenue per State in Million USD\n",
       "Region                                                                                                  \n",
       "Midwest                                            6026.04                                        209.06\n",
       "Northeast                                          4395.03                                        754.22\n",
       "South                                             11116.91                                        385.25\n",
       "West                                              14462.03                                         51.44"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revenue by region for each brand\n",
    "region_revenue = merged_df.groupby('Region')[['Starbucks est. Revenue per State in Million USD', \n",
    "                                       'Dunkin est. Revenue per State in Million USD']].sum()\n",
    "\n",
    "region_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Starbucks Revenue Share (%)</th>\n",
       "      <th>Dunkin Revenue Share (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>16.74</td>\n",
       "      <td>14.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northeast</th>\n",
       "      <td>12.21</td>\n",
       "      <td>53.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>30.88</td>\n",
       "      <td>27.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>40.17</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Starbucks Revenue Share (%)  Dunkin Revenue Share (%)\n",
       "Region                                                          \n",
       "Midwest                          16.74                     14.93\n",
       "Northeast                        12.21                     53.87\n",
       "South                            30.88                     27.52\n",
       "West                             40.17                      3.67"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Share of total revenue by region per brand # assisted by ChatGPT\n",
    "total_revenue = region_revenue.sum()\n",
    "\n",
    "# Calculate the share of total revenue per brand for each region\n",
    "region_revenue['Starbucks Revenue Share (%)'] = (region_revenue['Starbucks est. Revenue per State in Million USD'] / total_revenue['Starbucks est. Revenue per State in Million USD']) * 100\n",
    "region_revenue['Dunkin Revenue Share (%)'] = (region_revenue['Dunkin est. Revenue per State in Million USD'] / total_revenue['Dunkin est. Revenue per State in Million USD']) * 100\n",
    "\n",
    "reg_rev_share = pd.DataFrame.join(round(region_revenue['Starbucks Revenue Share (%)'], 2),round(region_revenue['Dunkin Revenue Share (%)'], 2))\n",
    "reg_rev_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Starbucks Revenue per Capita</th>\n",
       "      <th>Dunkin Revenue per Capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>190.204552</td>\n",
       "      <td>0.506851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>109.020897</td>\n",
       "      <td>0.972284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>95.679827</td>\n",
       "      <td>6.131435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>234.810385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>83.640373</td>\n",
       "      <td>10.468165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Starbucks Revenue per Capita  Dunkin Revenue per Capita\n",
       "0  California                    190.204552                   0.506851\n",
       "1       Texas                    109.020897                   0.972284\n",
       "2     Florida                     95.679827                   6.131435\n",
       "3  Washington                    234.810385                   0.000000\n",
       "4    New York                     83.640373                  10.468165"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revenue per capita for each state added to main dataframe merged_df # note: Assisted by ChatGPT\n",
    "merged_df['Starbucks Revenue per Capita'] = (merged_df['Starbucks est. Revenue per State in Million USD'] * 1e6) / merged_df['Population']\n",
    "merged_df['Dunkin Revenue per Capita'] = (merged_df['Dunkin est. Revenue per State in Million USD'] * 1e6) / merged_df['Population']\n",
    "\n",
    "merged_df[['State', 'Starbucks Revenue per Capita', 'Dunkin Revenue per Capita']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3765771295834709 0.5541588527688478\n",
      "0.3765771295834709 0.5541588527688478\n"
     ]
    }
   ],
   "source": [
    "# correlations between number of stores and est. revenue per capita in each state # note: assisted by ChatGPT\n",
    "starbucks_corr = merged_df[['Starbucks Revenue per Capita', 'Starbucks Stores 2023']].corr().iloc[0, 1]\n",
    "dunkin_corr = merged_df[['Dunkin Revenue per Capita', 'Dunkin Stores 2023']].corr().iloc[0, 1]\n",
    "\n",
    "print(starbucks_corr, dunkin_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, while both brands have more revenues in regions where their presence is highest, the correlation between revenue per capita and number of stores is higher for Dunkin than Starbucks. Considering a larger network of stores Starbucks and more presence in regions with larger populations, is a likely factors why this correlation metric is lower for Starbucks.\n",
    "\n",
    "note: Moving forwards, once we learn running regressions in Python, it may be interesting to do more advanced modelling and analysis eg. for estimated revenue per capita in states or regions where competitor presence is large or lower, for example with linear models and interaction variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# given already created a function 'ws_to_df' to scrape the html data into a dataframe, the only adjustment required is to add a column with a brand name.\n",
    "\n",
    "def ws_df_auto(url):\n",
    "    # scraping the data with BeautifulSoup\n",
    "    response = re.get(url)\n",
    "    soup_table = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Parsing all rows from the table\n",
    "    rows = soup_table.find_all('tr')\n",
    "\n",
    "    # Extracting headers (if present)\n",
    "    headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "    # Extract the brand name from the first header # assisted by ChatGPT\n",
    "    brand_name = headers[1].split()[0] if len(headers) > 1 else \"Unknown\"\n",
    "\n",
    "    # Initializing a list for the table\n",
    "    table_data = []\n",
    "\n",
    "    # Looping through rows to extract data\n",
    "    for row in rows[1:]: # skipping header extracted in prior step\n",
    "        state = row.find('a').text\n",
    "        values = [state] + [td.text.strip().replace(',','') for td in row.find_all('td')] ## assisted by ChatGPT\n",
    "        table_data.append(values)\n",
    "    \n",
    "    # Creating dataframe\n",
    "    df = pd.DataFrame(table_data, columns=headers)\n",
    "    \n",
    "    # adding column with brand_name\n",
    "    df['Brand'] = brand_name\n",
    "\n",
    "    # Print result\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Starbucks Stores 2023</th>\n",
       "      <th>Starbucks Stores 2021</th>\n",
       "      <th>Starbucks Stores 2024</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>3080</td>\n",
       "      <td>2959</td>\n",
       "      <td>3117</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1346</td>\n",
       "      <td>1215</td>\n",
       "      <td>1409</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>844</td>\n",
       "      <td>786</td>\n",
       "      <td>892</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>741</td>\n",
       "      <td>739</td>\n",
       "      <td>736</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>692</td>\n",
       "      <td>643</td>\n",
       "      <td>715</td>\n",
       "      <td>Starbucks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Starbucks Stores 2023 Starbucks Stores 2021 Starbucks Stores 2024      Brand\n",
       "0  California                  3080                  2959                  3117  Starbucks\n",
       "1       Texas                  1346                  1215                  1409  Starbucks\n",
       "2     Florida                   844                   786                   892  Starbucks\n",
       "3  Washington                   741                   739                   736  Starbucks\n",
       "4    New York                   692                   643                   715  Starbucks"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_df_auto('https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Dunkin Locations 2024</th>\n",
       "      <th>Dunkin Locations 2023</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>1431</td>\n",
       "      <td>1414</td>\n",
       "      <td>Dunkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1042</td>\n",
       "      <td>1068</td>\n",
       "      <td>Dunkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>909</td>\n",
       "      <td>883</td>\n",
       "      <td>Dunkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>872</td>\n",
       "      <td>866</td>\n",
       "      <td>Dunkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>711</td>\n",
       "      <td>692</td>\n",
       "      <td>Dunkin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           State Dunkin Locations 2024 Dunkin Locations 2023   Brand\n",
       "0       New York                  1431                  1414  Dunkin\n",
       "1  Massachusetts                  1042                  1068  Dunkin\n",
       "2        Florida                   909                   883  Dunkin\n",
       "3     New Jersey                   872                   866  Dunkin\n",
       "4       Illinois                   711                   692  Dunkin"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_df_auto('https://worldpopulationreview.com/state-rankings/dunkin-donuts-by-state').head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "raw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
